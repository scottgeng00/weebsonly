{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__main__\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n",
      "bad proxy\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from urllib.request import Request, urlopen\n",
    "from fake_useragent import UserAgent\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "startTime = datetime.now()\n",
    "print(__name__)\n",
    "\n",
    "# Here I provide some proxies for not getting caught while scraping\n",
    "ua = UserAgent() # From here we generate a random user agent\n",
    "test_url = r'https://myanimelist.net/animelist/cityhunter777/load.json'\n",
    "\n",
    "\n",
    "def get_proxies():\n",
    "    good_proxies = []      # Will contain the working proxies that can access mal\n",
    "    proxies = []           # Will contain proxies [ip, port]\n",
    "    \n",
    "    # Retrieve latest proxies\n",
    "    proxies_req = Request('https://www.sslproxies.org/')\n",
    "    proxies_req.add_header('User-Agent', ua.random)\n",
    "    proxies_doc = urlopen(proxies_req).read().decode('utf8')\n",
    "\n",
    "    soup = BeautifulSoup(proxies_doc, 'html.parser')\n",
    "    proxies_table = soup.find(id='proxylisttable')\n",
    "\n",
    "      # Save proxies in the array\n",
    "    for row in proxies_table.tbody.find_all('tr'):\n",
    "        proxies.append({\n",
    "        'ip':   row.find_all('td')[0].string,\n",
    "        'port': row.find_all('td')[1].string\n",
    "        })\n",
    "\n",
    "    #iterate through each of the proxies and delete the bad ones\n",
    "    \n",
    "    print(\"starting proxy test\")\n",
    "    \n",
    "    for n in range(len(proxies)):\n",
    "        if(len(good_proxies) > 3):\n",
    "            break\n",
    "        proxy = proxies[n]\n",
    "        req = Request(test_url)\n",
    "        req.set_proxy(proxy['ip'] + ':' + proxy['port'], 'http')\n",
    "        \n",
    "        # Try to make a call with the proxy\n",
    "        try:\n",
    "            my_ip = urlopen(req).read().decode('utf8')\n",
    "            print(proxy)\n",
    "            good_proxies.append(proxy)\n",
    "        except: # If error, move onto next\n",
    "            print(\"bad proxy\")\n",
    "    return good_proxies\n",
    "\n",
    "\n",
    "\n",
    "myproxies = get_proxies()\n",
    "\n",
    "\n",
    "\n",
    "# Retrieve a random index proxy (we need the index to delete it if not working)\n",
    "def random_proxy():\n",
    "    return random.randint(0, len(proxies) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for proxy in good_proxies:\n",
    "    req = Request(test_url)\n",
    "    req.add_header('User-Agent', ua.random)\n",
    "    req.set_proxy(proxy['ip'] + ':' + proxy['port'], 'http')\n",
    "    try:\n",
    "        response = urlopen(req)\n",
    "        print(proxy['ip'] + \" success\")\n",
    "    except:\n",
    "        print(proxy['ip'] + \" fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
